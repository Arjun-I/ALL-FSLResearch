<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scientist Meetings on Arjun Iyer</title>
    <link>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/</link>
    <description>Recent content in Scientist Meetings on Arjun Iyer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Meeting 1: Dr. Rajasekaran (Genentech) - 10/3/2021</title>
      <link>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-1/</guid>
      <description>Introduction with Dr. Kamal Rajasekaran
We gave Dr. Rajasekaran a brief overview of the project, presenting both a slideshow and a discussion of our dataset we plan to use for the purposes of the project.
Discussion of the Uniqueness of Our Proposal
We discussed about potential contacts Dr. Rajasekaran might have in the Digital Pathology department at Genentech who are experts in machine learning in cancer research.
Dr. Rajasekaran told us to refine the presentation a little bit to explain a little bit more about the parent model, child model, advantages, pitfalls, and how to overcome the pitfalls and forward it to him.</description>
    </item>
    
    <item>
      <title>Meeting 2: Dr. Schau (Genentech) - 10/13/2021</title>
      <link>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-2/</guid>
      <description>Key Topics Discussed During the Meeting
Dr. Schau recommended taking already existing weights from ImageNet, rather than pre training a model based on ImageNet. He said that this is because pre-training an existing model takes a longer amount of time and is more computationally expensive.
Discussion of Other Ways to Tackle Overfitting
Dr. Schau recommended K-fold cross validation as a good strategy to tackle overfitting, specifically 5-Fold cross validation. He also has offered to help us with code review, which will take place after we actually start training the model, and any other issues concerning our project.</description>
    </item>
    
    <item>
      <title>Meeting 3: Dr. Schau (Genentech) - 10/18/2021</title>
      <link>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://arjun-i.github.io/ALL-FSLResearch/scientist-meetings/meet-3/</guid>
      <description>Questions for Dr. Schau
Question 1: What kind of neural network design would be best for our research purposes? (eg. amount of nodes per layer, amount of layers, ex)
Answer: There are a lot of pre-existing models in FSL, and we can use that for our research purposes. ResNet might be too big for our problem, as we are dealing with small nuclei. We could use ResNet-50, but we could expand it to other neural network architectures.</description>
    </item>
    
  </channel>
</rss>
